{{/* the next line is obviously just for the generated file, not this template */}}
# This file is generated from libri.template.yml. Please edit that instead!
{{ $clusterAdminUser := .ClusterAdminUser -}}
{{ $libriVersion := .LibriVersion -}}
{{ $librarianDiskSizeGB := .LibrarianDiskSizeGB -}}
{{ $localPort := .LocalPort -}}
{{ $localMetricsPort := .LocalMetricsPort -}}
{{ $grafanaPort := .GrafanaPort -}}
{{ $prometheusPort := .PrometheusPort -}}
{{ $gcpCluster := .GCPCluster -}}
{{ $localCluster := .LocalCluster -}}
{{ $librarianCPULimit := .LibrarianCPULimit -}}
{{ $librarianRAMLimit := .LibrarianRAMLimit -}}
{{ $grafanaCPULimit := .GrafanaCPULimit -}}
{{ $grafanaRAMLimit := .GrafanaRAMLimit -}}
{{ $prometheusCPULimit := .PrometheusCPULimit -}}
{{ $prometheusRAMLimit := .PrometheusRAMLimit -}}
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: libri-experimenter
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: User
  name: {{ $clusterAdminUser }}
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: default-sa
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: default
    namespace: default
---
# headless service for internal DNS networking
kind: Service
apiVersion: v1
metadata:
  name: libri
  annotations:
    prometheus.io/scrape: "false"  # we get stats from individual pods
spec:
  clusterIP: None
  ports:
  - port: {{ $localPort }}
  selector:
    app: libri
---
{{ range $index, $librarian := .Librarians -}}
# NodePort service exposing the librarians-{{ $index }} node to the outside world
kind: Service
apiVersion: v1
metadata:
  name: librarians-{{ $index }}
  annotations:
    prometheus.io/scrape: "false"  # we get stats from individual pods
spec:
  type: NodePort
  ports:
  - port: {{ $localPort }}
    nodePort: {{ $librarian.PublicPort }}
  selector:
    hostname: librarians-{{ $index }}
---
# PersistentVolume for librarian {{ $index }}'s /data dir
kind: PersistentVolume
apiVersion: v1
metadata:
  name: data-librarians-{{ $index }}
  labels:
    app: libri
  annotations:
    volume.beta.kubernetes.io/storage-class: standard
spec:
  capacity:
    storage: {{ $librarianDiskSizeGB }}Gi
  accessModes: ["ReadWriteOnce"]
  {{ if $gcpCluster -}}
  gcePersistentDisk:
      fsType: "ext4"
      pdName: "data-librarians-{{ $index }}"
  {{ end -}}
  {{ if $localCluster -}}
  hostPath:
    path: "/data/data-librarians-{{ $index }}"
  {{ end }}
---
# PersistentVolumeClaim for librarian {{ $index }}'s PersistentVolume
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: data-librarians-{{ $index }}
  labels:
    app: libri
  annotations:
    volume.beta.kubernetes.io/storage-class: standard
spec:
  accessModes: ["ReadWriteOnce"]
  resources:
    requests:
      storage: {{ $librarianDiskSizeGB }}Gi
---
{{ end -}}
# StatefulSet of {{ .Librarians | len }} librarians
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: librarians
spec:
  serviceName: libri
  replicas: {{ .Librarians | len }}
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: libri
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "{{ $localMetricsPort }}"
    spec:
      containers:
      - name: libriarian
        image: daedalus2718/libri:{{ $libriVersion }}
        command: ["/bin/sh"]
        args:
          - "-c"
          - >
            libri librarian start
            --nSubscriptions 0
            --dataDir /data
            --localPort {{ $localPort }}
            --localMetricsPort {{ $localMetricsPort }}
            --publicHost $(wget -q -O - 'http://ipv4.myexternalip.com/raw')
            --publicPort $(HN=$(hostname) && echo $((30100 + ${HN##*-})))
            --bootstraps librarians-0.libri.default.svc.cluster.local:{{ $localPort }}
            --profile
        env:
        - name: GODEBUG         # ensure we use the pure Go (rather than CGO) DNS
          value: netdns=go      # resolver (see https://golang.org/src/net/net.go)
        - name: LIBRI_LOCALHOST
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        ports:
        - containerPort: {{ $localPort }}
        - containerPort: {{ $localMetricsPort }}
        livenessProbe:
          exec:
            command: [
              "sh", "-c",
              "libri", "test", "health",
              "-a", "$(hostname).libri.default.svc.cluster.local:{{ $localPort }}"
            ]
          initialDelaySeconds: 15
          periodSeconds: 30
        volumeMounts:
        - name: data
          mountPath: /data
        resources:
          limits:
            memory: {{ $librarianRAMLimit }}
            cpu: {{ $librarianCPULimit }}

      initContainers:
      - image: devth/k8s-labeler
        name: labeler
        env:
        - name: KUBE_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: KUBE_LABEL_hostname  # used to identify individual pods to each NodePort service
          valueFrom:
            fieldRef:
              fieldPath: metadata.name

      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: data

  volumeClaimTemplates:
  - metadata:
      name: data
---
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: node-exporter
spec:
  template:
    metadata:
      labels:
        app: node-exporter
      name: node-exporter
    spec:
      containers:
      - image: prom/node-exporter:v0.15.0
        name: node-exporter
        ports:
        - containerPort: 9100
          hostPort: 9100
          name: scrape
        resources:
          limits:
            memory: 100M
            cpu: 50m
      hostNetwork: true
      hostPID: true
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: default
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  labels:
    name: prometheus
  annotations:
      prometheus.io/scrape: 'true'
spec:
  selector:
    app: prometheus
  type: NodePort  # prob want to move behind LB at some point
  ports:
  - name: prometheus
    protocol: TCP
    port: 9090
    targetPort: 9090
    nodePort: {{ $prometheusPort }}
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: prometheus
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      name: prometheus
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.0.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.retention=15d'
#          - '-alertmanager.url=http://alertmanager:9093/alertmanager'
#          - '-web.external-url=$(EXTERNAL_URL)'
        ports:
        - name: web
          containerPort: 9090
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
#        - name: rules-volume
#          mountPath: /etc/prometheus-rules
#        - name: prometheus-data
#          mountPath: /prometheus
        resources:
          limits:
            memory: {{ $prometheusRAMLimit }}
            cpu: {{ $prometheusCPULimit }}
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
#      - name: rules-volume
#        configMap:
#          name: prometheus-rules
#      - name: prometheus-data
#        emptyDir: {}  # TODO (drausin) PeristentVolume
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  labels:
    app: grafana
  annotations:
      prometheus.io/scrape: 'false'
spec:
  selector:
    app: grafana
  type: NodePort  # prob want to move behind LB at some point
  ports:
  - name: grafana
    protocol: TCP
    port: 3000
    targetPort: 3000
    nodePort: {{ $grafanaPort }}
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: grafana
  labels:
    app: grafana
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - image: grafana/grafana:4.6.2
        name: grafana
        env:
            # The following env variables are required to make Grafana accessible via
            # the kubernetes api-server proxy. On production clusters, we recommend
            # removing these env variables, setup auth for grafana, and expose the grafana
            # service using a LoadBalancer or a public IP.
          - name: GF_AUTH_BASIC_ENABLED
            value: "false"
          - name: GF_AUTH_ANONYMOUS_ENABLED
            value: "true"
          - name: GF_AUTH_ANONYMOUS_ORG_ROLE
            value: Admin
          # - name: GF_SERVER_ROOT_URL
          #   value: /api/v1/proxy/namespaces/kube-system/services/monitoring-grafana/
        resources:
          limits:
            memory: {{ $grafanaRAMLimit }}
            cpu: {{ $grafanaCPULimit }}

        lifecycle:
          postStart:
            exec:
              command: [
                "sh", "/opt/grafana/post-start.sh", "http://localhost:3000"
              ]

        volumeMounts:
        - name: grafana-config
          mountPath: /opt/grafana

      volumes:
      - name: grafana-config
        configMap:
          name: grafana-config
